/*
 * The general modelling and simulation framework JAMES II.
 * Copyright by the University of Rostock.
 * 
 * LICENCE: JAMESLIC
 */
package org.jamesii.simspex.spdm.evaluation.bootstrapping;


import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.jamesii.SimSystem;
import org.jamesii.asf.spdm.Features;
import org.jamesii.asf.spdm.dataimport.PerformanceDataSet;
import org.jamesii.asf.spdm.dataimport.PerformanceTuple;
import org.jamesii.asf.spdm.generators.IPerformancePredictor;
import org.jamesii.asf.spdm.generators.plugintype.IPerformancePredictorGenerator;
import org.jamesii.asf.spdm.generators.plugintype.PerformancePredictorGeneratorFactory;
import org.jamesii.asf.spdm.util.PerformanceTuples;
import org.jamesii.core.math.random.generators.IRandom;
import org.jamesii.core.parameters.ParameterBlock;
import org.jamesii.core.util.misc.Pair;
import org.jamesii.simspex.spdm.evaluation.IPredictorGeneratorEvaluationStrategy;
import org.jamesii.simspex.spdm.evaluation.evaluator.FullPredictorEvaluator;
import org.jamesii.simspex.spdm.evaluation.evaluator.IPredictorEvaluator;
import org.jamesii.simspex.spdm.evaluation.perfmeasures.PredictorPerformance;

/**
 * 0.632 bootstrapping, a method to divide test and training sets for error
 * estimation of machine learners (see Frank and Witten, "Data Mining: Practical
 * Machine Learning Tools and Techniques". Morgan Kaufmann 2005).
 * 
 * @author Steffen Torbahn
 * @author Roland Ewald
 * 
 */
public class BootStrapping implements IPredictorGeneratorEvaluationStrategy {

  /** Number of passes (repetitions). */
  private final int numPasses;

  /** Random number generator. */
  private IRandom rand = SimSystem.getRNGGenerator().getNextRNG();

  /**
   * Default constructor.
   * 
   * @param numberOfPasses
   *          number of passes
   */
  public BootStrapping(int numberOfPasses) {
    numPasses = numberOfPasses;
  }

  /**
   * Returns a pair of test and training data generated by the bootstrapping
   * algorithm.
   * 
   * @param data
   *          list of overall data tuples
   * @return pair of lists of data elements: (training,test)
   */
  protected Pair<List<PerformanceTuple>, List<PerformanceTuple>> bootStrap(
      List<PerformanceTuple> data) {

    // Bootstrap over distinct model features
    List<Features> allFeatures = new ArrayList<>();
    List<Features> trainingFeatures = new ArrayList<>();
    List<Features> testFeatures = new ArrayList<>();
    Map<Features, List<PerformanceTuple>> featureMap =
        PerformanceTuples.sortToFeatureMap(data);
    allFeatures.addAll(featureMap.keySet());

    fillFeatureListsByBootStrap(allFeatures, trainingFeatures, testFeatures);

    List<PerformanceTuple> trainingData =
        PerformanceTuples.getTuplesForFeatures(featureMap, trainingFeatures);
    List<PerformanceTuple> testData =
        PerformanceTuples.getTuplesForFeatures(featureMap, testFeatures);
    return new Pair<>(
        trainingData, testData);
  }

  /**
   * Fills feature list by bootstrapping, takes care that list of test features
   * is non-empty.
   * 
   * @param allFeatures
   *          list of all features
   * @param trainingFeatures
   *          list of training features
   * @param testFeatures
   *          list of test features
   */
  private void fillFeatureListsByBootStrap(List<Features> allFeatures,
      List<Features> trainingFeatures, List<Features> testFeatures) {
    // Method only works when at least two elements exist (one for test, one for
    // training)
    if (allFeatures.size() < 2) {
      return;
    }

    do {
      trainingFeatures.clear();
      Set<Integer> trainingIndices =
          org.jamesii.core.math.statistics.Resampling.bootStrap(allFeatures,
              trainingFeatures, rand);
      // Put every element not belonging to training data
      // into test data
      for (int i = 0; i < allFeatures.size(); i++) {
        if (trainingIndices.contains(i)) {
          continue;
        }
        testFeatures.add(allFeatures.get(i));
      }
      // If test features are empty (unlucky), repeat
    } while (testFeatures.isEmpty());
  }

  @Override
  public List<PredictorPerformance> evaluatePredictorGenerator(
      PerformancePredictorGeneratorFactory selGenFactory,
      PerformanceDataSet dataSet, ParameterBlock parameters) {
    List<PredictorPerformance> result = new ArrayList<>();
    for (int i = 0; i < numPasses; i++) {
      PredictorPerformance selPerf =
          createAndTestPredictor(selGenFactory, dataSet, parameters);
      result.add(selPerf);
    }
    return result;
  }

  /**
   * Creates and tests a predictor.
   * 
   * @param predGenFactory
   *          the predictor generator factory
   * @param dataSet
   *          the data set
   * @param parameters
   *          the parameters
   * 
   * @return the predictor performance
   */
  PredictorPerformance createAndTestPredictor(
      PerformancePredictorGeneratorFactory predGenFactory,
      PerformanceDataSet dataSet, ParameterBlock parameters) {
    List<PerformanceTuple> data = dataSet.getInstances();
    Pair<List<PerformanceTuple>, List<PerformanceTuple>> bootstrapData =
        bootStrap(data);
    IPerformancePredictorGenerator predGen =
        predGenFactory.createPredictorGenerator(parameters, data.get(0));
    IPerformancePredictor predictor =
        predGen.generatePredictor(bootstrapData.getFirstValue(),
            dataSet.getMetaData());
    IPredictorEvaluator sev = new FullPredictorEvaluator();
    PredictorPerformance selPerf =
        sev.evaluate(predictor, bootstrapData.getFirstValue(),
            bootstrapData.getSecondValue(), parameters);
    return selPerf;
  }
}
